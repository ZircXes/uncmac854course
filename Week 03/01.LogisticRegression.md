# Logistic Regression and Classification in Python
Logistic regression is a classification technique that constrains solutions between 0 and 1, typically interpreted as a percentage of a binary outcome.

Similar to linear regression, the technique takes numerical data as inputs, although the data is transformed so the relative impact of a variable is unchanged but the absolute impact of a variable changes along the curve.

The Sci-Kit learn logistic regression module we will use in Python does not provide the same results as our Excel methodology because Sci-Kit learn applies regularization by default. We can adjust the module to solve for the traditional result by overriding the penalty parameter.


### Video
[Video] - placeholder


### Logistic Regression in Sci-Kit Learn
Sci-Kit learn offers many types of logistic regression, with a flexible regularization framework that offers ElasticNet and Classical logistic regression.
* Classical logistic regression
* L<sub>2</sub> Regularization
* L<sub>1</sub> Regularization
* ElasticNet (L<sub>1</sub> and L<sub>2</sub> Regularization)

Regularization expands on classical regression by adding one or more hyperparameters that affects model performance. Hyperparameters are simply parameters that are selected prior to model construction. Choosing hyperparameters appropriately impacts the performance of the model.

The hyperparameter for logistic regression is *C* which is the inverse of the *λ* from linear regression. A smaller parameter *C* implies stronger regularization.

### Logistic Regression in Python
Libraries
```
import pandas as pd 
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, roc_curve, auc
```

Key Steps
1. Prepare your data for regression
2. Break your dataframe into an X and a Y dataset
3. Define the model with hyperparameters
4. Fit the model
5. Make predictions
6. Measure performance


Fitting Logistic Regression (Classical)
```
LRmodel = LogisticRegression(solver="lbfgs",  penalty='none', random_state=42)
model = LRmodel.fit(X, y)
```

Fitting Logistic Regression with L2 Regularization
```
RRmodel = LogisticRegression(solver="lbfgs", random_state=42, C = 0.1)
model = RRmodel.fit(X, y)
```

Making Predictions
```
yp = model.predict(X)
y_score = model.decision_function(X)
```

Measuring Performance with a confusion matrix
```
tn, fp, fn, tp = confusion_matrix(y, yp).ravel()

fpr, tpr, thresholds = roc_curve(y, y_score)

roc_auc = auc(fpr, tpr)
```

Getting coefficients
```
print(model.intercept_) print(model.coef_)
```

Interpreting your Logistic Regression Model
Confusion matrix values

[placeholder]
ROC Curves

[placeholder]

Plotting ROC
Using MatplotLib
```
import patplotlib.pyplot as plt
plt.figure()
plt.plot([0, 1],[1,1], color='black', linestyle='--', lw=1)
plt.plot(fpr,tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc, l
w=2)
plt.plot([0, 1],[0,1], color='navy', linestyle='--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()
```

Full Code Examples
1. UNC Demo
   a. Compare classical logistic regression and regularized logistic regression


### References

#### FAQ
[Placeholder]


### Support Links
1. [SKLearn documentation: Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)
2. [Géron - Chapter 03 - Classification Models](https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb)
